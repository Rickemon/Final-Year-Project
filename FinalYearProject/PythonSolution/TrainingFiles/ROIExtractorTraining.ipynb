{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libaries"
      ],
      "metadata": {
        "id": "2rl7jlTHXffa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON1OGUr_EuzD",
        "outputId": "ddae64e0-d280-46c7-ccdb-3637ce0fb26a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential, Model \n",
        "from tensorflow.keras.layers import Input, Dropout, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Reshape, concatenate \n"
      ],
      "metadata": {
        "id": "JJ4CYdF_GJbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up on-demand loading"
      ],
      "metadata": {
        "id": "thHzd1LoXiAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/Final Year Project  /Data'#training data comes from multiple sources and they are stored in the 'data' folder"
      ],
      "metadata": {
        "id": "u2mnpHcCGJpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dirs = [root+'/G1020/Images', root+'/ORIGA/Images']\n",
        "mask_dirs = [root+'/G1020/ROI', root+'/ORIGA/ROI']"
      ],
      "metadata": {
        "id": "P5lZdxHkMCeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list of all image file paths\n",
        "input_files = []\n",
        "for dir in input_dirs:\n",
        "    input_files.extend([os.path.join(dir, f) for f in sorted(os.listdir(dir))])\n",
        "\n",
        "#list of all mask file paths\n",
        "mask_files = []\n",
        "for dir in mask_dirs:\n",
        "    mask_files.extend([os.path.join(dir, f) for f in sorted(os.listdir(dir))])\n",
        "\n",
        "#DataFrame with both file paths\n",
        "data = pd.DataFrame({'input': input_files, 'mask': mask_files})\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "zf6_TbJIMAha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "# Define the data generator for the input images\n",
        "image_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "#data generator for the mask images is seperate\n",
        "#as rescale would damage the mask\n",
        "mask_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "# Create the generator for the input images\n",
        "image_generator = image_datagen.flow_from_dataframe(\n",
        "    dataframe=data,\n",
        "    x_col='input',\n",
        "    y_col=None,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode=None,\n",
        ")\n",
        "\n",
        "# Create the generator for the mask images\n",
        "mask_generator = mask_datagen.flow_from_dataframe(\n",
        "    dataframe=data,\n",
        "    x_col='mask',\n",
        "    y_col=None,\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode=None,\n",
        "    color_mode='grayscale'\n",
        ")\n",
        "train_generator = zip(image_generator, mask_generator)      "
      ],
      "metadata": {
        "id": "Nc1uNfX8OvIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = custom_image_mask_generator(train_data, batch_size=32, target_size=(256, 256))\n",
        "test_generator = custom_image_mask_generator(test_data, batch_size=32, target_size=(256, 256))"
      ],
      "metadata": {
        "id": "nnKLTjqCVnzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Designing the UNet architeture"
      ],
      "metadata": {
        "id": "lN-t6Sx8XSGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(256, 256, 3))\n",
        "\n",
        "# Contracting path\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "drop4 = Dropout(0.5)(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "# Expansive path\n",
        "up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
        "merge6 = concatenate([drop4, up6], axis=3)\n",
        "conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
        "merge7 = concatenate([conv3, up7], axis=3)\n",
        "conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
        "merge8 = concatenate([conv2, up8], axis=3)\n",
        "conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "\n",
        "up9 = UpSampling2D(size=(2,2))(conv8)\n",
        "up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up9)\n",
        "merge9 = concatenate([conv1,up9], axis=3)\n",
        "conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "\n",
        "conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "# Define the model\n",
        "model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "o8A3W64eR1Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,\n",
        "          steps_per_epoch=len(data) // 32,\n",
        "          epochs=10)"
      ],
      "metadata": {
        "id": "o1xWnXWbY0po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.models.save_model(model, '/content/drive/MyDrive/Final Year Project  /Models/ROIExstractor.h5')"
      ],
      "metadata": {
        "id": "l4JPfUusddMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('/content/drive/MyDrive/Final Year Project  /Models/ROIExstractor.h5')"
      ],
      "metadata": {
        "id": "1hz7SC_w_3yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "YucjBVmq2o7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(mask_files[0])\n",
        "\n",
        "height, width = image.shape[:2]\n",
        "\n",
        "aspect_ratio = float(width) / float(height)\n",
        "\n",
        "if height > width:\n",
        "    new_height = 256\n",
        "    new_width = int(new_height * aspect_ratio)\n",
        "else:\n",
        "    new_width = 256\n",
        "    new_height = int(new_width / aspect_ratio)\n",
        "\n",
        "resized_img = cv2.resize(image, (new_width, new_height))\n",
        "\n",
        "background = np.zeros((256, 256, 3), dtype=np.uint8)\n",
        "\n",
        "x_offset = int((256 - new_width) / 2)\n",
        "y_offset = int((256 - new_height) / 2)\n",
        "\n",
        "background[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_img\n",
        "image = background\n",
        "\n",
        "image = np.expand_dims(image, axis=0)"
      ],
      "metadata": {
        "id": "M27dFZF8AKG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(image)"
      ],
      "metadata": {
        "id": "7A4BGjswAc0D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}